{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a737fb8e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-13T10:53:33.726580Z",
     "iopub.status.busy": "2023-11-13T10:53:33.725908Z",
     "iopub.status.idle": "2023-11-13T10:53:35.422355Z",
     "shell.execute_reply": "2023-11-13T10:53:35.421290Z"
    },
    "papermill": {
     "duration": 1.703506,
     "end_time": "2023-11-13T10:53:35.424694",
     "exception": false,
     "start_time": "2023-11-13T10:53:33.721188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TRON'...\r\n",
      "remote: Enumerating objects: 154, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (154/154), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\r\n",
      "remote: Total 154 (delta 84), reused 143 (delta 73), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (154/154), 1.91 MiB | 27.60 MiB/s, done.\r\n",
      "Resolving deltas: 100% (84/84), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/UwU-tao/TRON.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a60331a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:53:35.433601Z",
     "iopub.status.busy": "2023-11-13T10:53:35.433292Z",
     "iopub.status.idle": "2023-11-13T10:53:35.439507Z",
     "shell.execute_reply": "2023-11-13T10:53:35.438678Z"
    },
    "papermill": {
     "duration": 0.012776,
     "end_time": "2023-11-13T10:53:35.441438",
     "exception": false,
     "start_time": "2023-11-13T10:53:35.428662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TRON\n"
     ]
    }
   ],
   "source": [
    "%cd TRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1e4de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:53:35.449747Z",
     "iopub.status.busy": "2023-11-13T10:53:35.449448Z",
     "iopub.status.idle": "2023-11-13T10:56:42.553428Z",
     "shell.execute_reply": "2023-11-13T10:56:42.552265Z"
    },
    "papermill": {
     "duration": 187.110702,
     "end_time": "2023-11-13T10:56:42.555799",
     "exception": false,
     "start_time": "2023-11-13T10:53:35.445097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipenv\r\n",
      "  Obtaining dependency information for pipenv from https://files.pythonhosted.org/packages/1c/18/5f429a08ae4d43d6037f9896c6f69f101900d8cb66afc0ccad1d592b3864/pipenv-2023.10.24-py3-none-any.whl.metadata\r\n",
      "  Downloading pipenv-2023.10.24-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pipenv) (2023.7.22)\r\n",
      "Requirement already satisfied: setuptools>=67 in /opt/conda/lib/python3.10/site-packages (from pipenv) (68.1.2)\r\n",
      "Collecting virtualenv>=20.24.2 (from pipenv)\r\n",
      "  Obtaining dependency information for virtualenv>=20.24.2 from https://files.pythonhosted.org/packages/7f/19/1f0eddcb9acf00a95793ce83417f69e0fd106c192121360af499cd6fde39/virtualenv-20.24.6-py3-none-any.whl.metadata\r\n",
      "  Downloading virtualenv-20.24.6-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.24.2->pipenv) (0.3.7)\r\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.24.2->pipenv) (3.12.2)\r\n",
      "Requirement already satisfied: platformdirs<4,>=3.9.1 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.24.2->pipenv) (3.11.0)\r\n",
      "Downloading pipenv-2023.10.24-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading virtualenv-20.24.6-py3-none-any.whl (3.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: virtualenv, pipenv\r\n",
      "  Attempting uninstall: virtualenv\r\n",
      "    Found existing installation: virtualenv 20.21.0\r\n",
      "    Uninstalling virtualenv-20.21.0:\r\n",
      "      Successfully uninstalled virtualenv-20.21.0\r\n",
      "Successfully installed pipenv-2023.10.24 virtualenv-20.24.6\r\n",
      "\u001b[1mCreating a virtualenv for this project...\u001b[0m\r\n",
      "Pipfile: \u001b[33m\u001b[1m/kaggle/working/TRON/Pipfile\u001b[0m\r\n",
      "\u001b[1mUsing\u001b[0m \u001b[33m\u001b[1m/opt/conda/bin/python3.1\u001b[0m \u001b[32m(3.10.12)\u001b[0m \u001b[1mto create virtualenv...\u001b[0m\r\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Creating virtual environment...\u001b[36mcreated virtual environment CPython3.10.12.final.0-64 in 1459ms\r\n",
      "  creator CPython3Posix(dest=/root/.local/share/virtualenvs/TRON-qh2Xl1Tx, clear=False, no_vcs_ignore=False, global=False)\r\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\r\n",
      "    added seed packages: pip==23.3.1, setuptools==68.2.2, wheel==0.41.2\r\n",
      "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\r\n",
      "\u001b[0m\r\n",
      "✔ Successfully created virtual environment!\r\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Creating virtual environment...\r\n",
      "\u001b[1A\u001b[2K\u001b[32mVirtualenv location: /root/.local/share/virtualenvs/TRON-qh2Xl1Tx\u001b[0m\r\n",
      "\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m360c9d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date, updating to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m155ce2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\r\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\r\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\r\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\r\n",
      "\u001b[2K✔ Success!\r\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking...\r\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\r\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\r\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\r\n",
      "\u001b[2K✔ Success!\r\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Locking...\r\n",
      "\u001b[1A\u001b[2K\u001b[1mUpdated Pipfile.lock (13adccd5b977e7343bb68836846afacdcf46b09c0f953b06a00a1093e5155ce2)!\u001b[0m\r\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m155ce2\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\r\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m155ce2\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\r\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\r\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pipenv\n",
    "!pipenv install --dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a70de2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:56:42.689859Z",
     "iopub.status.busy": "2023-11-13T10:56:42.689436Z",
     "iopub.status.idle": "2023-11-13T10:56:48.433060Z",
     "shell.execute_reply": "2023-11-13T10:56:48.432130Z"
    },
    "papermill": {
     "duration": 5.813995,
     "end_time": "2023-11-13T10:56:48.435391",
     "exception": false,
     "start_time": "2023-11-13T10:56:42.621396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.10.12, pytest-7.4.3, pluggy-1.3.0\r\n",
      "rootdir: /kaggle/working/TRON\r\n",
      "collected 55 items                                                             \u001b[0m\r\n",
      "\r\n",
      "test/test_evaluate.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                            [ 12%]\u001b[0m\r\n",
      "test/test_gru_dataset.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                           [ 21%]\u001b[0m\r\n",
      "test/test_gru_model.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                           [ 34%]\u001b[0m\r\n",
      "test/test_logits_computation.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                 [ 49%]\u001b[0m\r\n",
      "test/test_loss.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                               [ 63%]\u001b[0m\r\n",
      "test/test_preprocessing.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                           [ 69%]\u001b[0m\r\n",
      "test/test_sample.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                              [ 81%]\u001b[0m\r\n",
      "test/test_sas_dataset.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                            [ 89%]\u001b[0m\r\n",
      "test/test_sas_model.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                            [100%]\u001b[0m\r\n",
      "\r\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\r\n",
      "../../../root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/lightning_utilities/core/imports.py:13\r\n",
      "  /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/lightning_utilities/core/imports.py:13: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n",
      "\r\n",
      "../../../root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/lightning_fabric/__init__.py:40\r\n",
      "  /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/lightning_fabric/__init__.py:40: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.\r\n",
      "  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n",
      "\r\n",
      "../../../root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torchmetrics/utilities/imports.py:24\r\n",
      "../../../root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torchmetrics/utilities/imports.py:24\r\n",
      "  /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torchmetrics/utilities/imports.py:24: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\r\n",
      "    _PYTHON_LOWER_3_8 = LooseVersion(_PYTHON_VERSION) < LooseVersion(\"3.8\")\r\n",
      "\r\n",
      "../../../root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/pytorch_lightning/__init__.py:37\r\n",
      "  /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/pytorch_lightning/__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\r\n",
      "  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\r\n",
      "\r\n",
      "test/test_gru_dataset.py::test_dataset\r\n",
      "test/test_gru_dataset.py::test_datalaoder\r\n",
      "  /kaggle/working/TRON/src/gru4rec/dataset.py:63: UserWarning: Warning eventwise is not supported and is set to sessionwise ...\r\n",
      "    warnings.warn(\"Warning eventwise is not supported and is set to sessionwise ...\")\r\n",
      "\r\n",
      "test/test_gru_model.py::test_training_step_shared_no_bias\r\n",
      "test/test_gru_model.py::test_training_step_not_shared_no_bias\r\n",
      "test/test_gru_model.py::test_training_step_not_shared_bias\r\n",
      "test/test_gru_model.py::test_validation_step\r\n",
      "test/test_sas_model.py::test_training_step\r\n",
      "test/test_sas_model.py::test_training_step_not_shared_output_bias\r\n",
      "test/test_sas_model.py::test_training_step_not_shared_output_no_output_bias\r\n",
      "test/test_sas_model.py::test_validation_step\r\n",
      "  /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/pytorch_lightning/core/module.py:420: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\r\n",
      "\r\n",
      "test/test_gru_model.py::test_training_step_not_shared_bias\r\n",
      "  /kaggle/working/TRON/src/gru4rec/model.py:63: UserWarning: Warning gru original cannot share input and output embeddings, share embedding is set to False\r\n",
      "    warnings.warn(\"Warning gru original cannot share input and output embeddings, share embedding is set to False\")\r\n",
      "\r\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n",
      "\u001b[33m======================= \u001b[32m55 passed\u001b[0m, \u001b[33m\u001b[1m16 warnings\u001b[0m\u001b[33m in 3.09s\u001b[0m\u001b[33m ========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pipenv run pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39c197d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:56:48.610904Z",
     "iopub.status.busy": "2023-11-13T10:56:48.610561Z",
     "iopub.status.idle": "2023-11-13T10:56:55.973495Z",
     "shell.execute_reply": "2023-11-13T10:56:55.972535Z"
    },
    "papermill": {
     "duration": 7.432221,
     "end_time": "2023-11-13T10:56:55.975735",
     "exception": false,
     "start_time": "2023-11-13T10:56:48.543514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "gzip is already the newest version (1.10-4ubuntu4.1).\r\n",
      "unzip is already the newest version (6.0-26ubuntu3.1).\r\n",
      "The following NEW packages will be installed:\r\n",
      "  7zip\r\n",
      "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\r\n",
      "Need to get 971 kB of archives.\r\n",
      "After this operation, 2454 kB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 7zip amd64 21.07+dfsg-4 [971 kB]\r\n",
      "Fetched 971 kB in 1s (1662 kB/s)\r\n",
      "Selecting previously unselected package 7zip.\r\n",
      "(Reading database ... 114840 files and directories currently installed.)\r\n",
      "Preparing to unpack .../7zip_21.07+dfsg-4_amd64.deb ...\r\n",
      "Unpacking 7zip (21.07+dfsg-4) ...\r\n",
      "Setting up 7zip (21.07+dfsg-4) ...\r\n",
      "Processing triggers for man-db (2.10.2-1) ...\r\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install 7zip gzip unzip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf50c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:56:56.116248Z",
     "iopub.status.busy": "2023-11-13T10:56:56.115904Z",
     "iopub.status.idle": "2023-11-13T11:13:29.855157Z",
     "shell.execute_reply": "2023-11-13T11:13:29.853913Z"
    },
    "papermill": {
     "duration": 994.408055,
     "end_time": "2023-11-13T11:13:30.453752",
     "exception": false,
     "start_time": "2023-11-13T10:56:56.045697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yoochoose\r\n",
      "--2023-11-13 10:56:56--  https://s3-eu-west-1.amazonaws.com/yc-rdata/yoochoose-data.7z\r\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.96.242, 52.218.30.91, 52.218.97.59, ...\r\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.96.242|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 287211932 (274M) [application/octet-stream]\r\n",
      "Saving to: ‘datasets/yoochoose/yoochoose-data.7z’\r\n",
      "\r\n",
      "yoochoose-data.7z   100%[===================>] 273.91M  26.9MB/s    in 11s     \r\n",
      "\r\n",
      "2023-11-13 10:57:09 (23.9 MB/s) - ‘datasets/yoochoose/yoochoose-data.7z’ saved [287211932/287211932]\r\n",
      "\r\n",
      "\r\n",
      "7-Zip (z) 21.07 (x64) : Copyright (c) 1999-2021 Igor Pavlov : 2021-12-26\r\n",
      " 64-bit locale=C.UTF-8 Threads:4\r\n",
      "\r\n",
      "Scanning the drive for archives:\r\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 287211932 bytes (274 MiB)\r\n",
      "\r\n",
      "Extracting archive: datasets/yoochoose/yoochoose-data.7z\r\n",
      "--\r\n",
      "Path = datasets/yoochoose/yoochoose-data.7z\r\n",
      "Type = 7z\r\n",
      "Physical Size = 287211932\r\n",
      "Headers Size = 255\r\n",
      "Method = LZMA:24\r\n",
      "Solid = +\r\n",
      "Blocks = 2\r\n",
      "\r\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 3\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\r\n",
      "\r\n",
      "Files: 4\r\n",
      "Size:       1914111754\r\n",
      "Compressed: 287211932\r\n",
      "Preprocessing yoochoose\r\n",
      "INFO:root:Running preprocessing for yoochoose dataset\r\n",
      "INFO:root:Read 33003944 events from datasets/yoochoose/yoochoose-clicks.dat\r\n",
      "INFO:root:Creating sessions...\r\n",
      "100%|████████████████████████████| 33003944/33003944 [10:34<00:00, 52002.07it/s]\r\n",
      "INFO:root:Created 9249729 sessions for yoochoose\r\n",
      "INFO:root:Filtering sessions...\r\n",
      "100%|████████████████████████████| 9249729/9249729 [00:04<00:00, 2074062.63it/s]\r\n",
      "100%|█████████████████████████████| 7990018/7990018 [00:23<00:00, 344550.17it/s]\r\n",
      "100%|████████████████████████████| 7990018/7990018 [00:03<00:00, 2044551.36it/s]\r\n",
      "INFO:root:Remaining sessions after filtering: 7981581\r\n",
      "INFO:root:Splitting sessions into train and test...\r\n",
      "INFO:root:Split sessions into 7966257 train and 15324 test sessions\r\n",
      "100%|█████████████████████████████████| 15324/15324 [00:00<00:00, 960567.83it/s]\r\n",
      "INFO:root:Remaining test sessions after filtering: 15324\r\n",
      "INFO:root:Creating item indices...\r\n",
      "100%|██████████████████████████| 31637239/31637239 [00:13<00:00, 2433110.12it/s]\r\n",
      "INFO:root:Created 37483 item indices\r\n",
      "INFO:root:Remapping item indices...\r\n",
      "100%|█████████████████████████████| 7966257/7966257 [00:18<00:00, 437169.65it/s]\r\n",
      "100%|█████████████████████████████████| 15324/15324 [00:00<00:00, 282666.31it/s]\r\n",
      "INFO:root:Sorting sessions\r\n",
      "INFO:root:Writing sessions to datasets/yoochoose\r\n",
      "100%|██████████████████████████████| 7966257/7966257 [02:15<00:00, 58909.03it/s]\r\n",
      "100%|██████████████████████████████████| 15324/15324 [00:00<00:00, 54969.30it/s]\r\n",
      "INFO:root:Writing stats to datasets/yoochoose/yoochoose_stats.json\r\n",
      "INFO:root:All done!\r\n"
     ]
    }
   ],
   "source": [
    "!bash prepare.sh yoochoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9198cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T11:13:31.951498Z",
     "iopub.status.busy": "2023-11-13T11:13:31.950767Z",
     "iopub.status.idle": "2023-11-13T12:19:29.552760Z",
     "shell.execute_reply": "2023-11-13T12:19:29.551783Z"
    },
    "papermill": {
     "duration": 3958.309105,
     "end_time": "2023-11-13T12:19:29.555032",
     "exception": false,
     "start_time": "2023-11-13T11:13:31.245927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/lightning_fabric/connector.py:565: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\r\n",
      "Using 16bit Automatic Mixed Precision (AMP)\r\n",
      "GPU available: True (cuda), used: True\r\n",
      "TPU available: False, using: 0 TPU cores\r\n",
      "IPU available: False, using: 0 IPUs\r\n",
      "HPU available: False, using: 0 HPUs\r\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\r\n",
      "2023/11/13 11:13:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/mlflow/pytorch/_lightning_autolog.py:351: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.4.9 and 2.1.0 and may not succeed with packages outside this range.\"\r\n",
      "Missing logger folder: /kaggle/working/TRON/lightning_logs\r\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\r\n",
      "\r\n",
      "  | Name                       | Type                     | Params\r\n",
      "------------------------------------------------------------------------\r\n",
      "0 | item_embedding             | Embedding                | 7.5 M \r\n",
      "1 | positional_embedding_layer | DynamicPositionEmbedding | 10.0 K\r\n",
      "2 | norm                       | LayerNorm                | 400   \r\n",
      "3 | input_dropout              | Dropout                  | 0     \r\n",
      "4 | encoder                    | TransformerEncoder       | 484 K \r\n",
      "5 | final_activation           | Identity                 | 0     \r\n",
      "------------------------------------------------------------------------\r\n",
      "8.0 M     Trainable params\r\n",
      "0         Non-trainable params\r\n",
      "8.0 M     Total params\r\n",
      "31.965    Total estimated model params size (MB)\r\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\r\n",
      "/root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: You called `self.log('test_seq_len', ...)` in your `validation_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'test_seq_len': ...})` instead.\r\n",
      "Epoch 0: 100%|█████████████████| 62236/62236 [1:05:14<00:00, 15.90it/s, v_num=0]\r\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation:   0%|                                       | 0/119 [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   0%|                          | 0/119 [00:00<?, ?it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   1%|▏                 | 1/119 [00:00<00:15,  7.81it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   2%|▎                 | 2/119 [00:00<00:13,  8.46it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   3%|▍                 | 3/119 [00:00<00:12,  9.07it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   3%|▌                 | 4/119 [00:00<00:12,  9.08it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   4%|▊                 | 5/119 [00:00<00:11,  9.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   5%|▉                 | 6/119 [00:00<00:11, 10.13it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   6%|█                 | 7/119 [00:00<00:10, 10.43it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   7%|█▏                | 8/119 [00:00<00:10, 10.74it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   8%|█▎                | 9/119 [00:00<00:10, 10.86it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   8%|█▍               | 10/119 [00:00<00:09, 11.07it/s]\u001b[A\r\n",
      "Validation DataLoader 0:   9%|█▌               | 11/119 [00:00<00:09, 11.23it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  10%|█▋               | 12/119 [00:01<00:09, 11.38it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  11%|█▊               | 13/119 [00:01<00:09, 11.52it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  12%|██               | 14/119 [00:01<00:09, 11.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  13%|██▏              | 15/119 [00:01<00:08, 11.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  13%|██▎              | 16/119 [00:01<00:08, 11.74it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  14%|██▍              | 17/119 [00:01<00:08, 11.81it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  15%|██▌              | 18/119 [00:01<00:08, 11.87it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  16%|██▋              | 19/119 [00:01<00:08, 11.91it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  17%|██▊              | 20/119 [00:01<00:08, 11.90it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  18%|███              | 21/119 [00:01<00:08, 11.97it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  18%|███▏             | 22/119 [00:01<00:08, 12.06it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  19%|███▎             | 23/119 [00:01<00:07, 12.13it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  20%|███▍             | 24/119 [00:01<00:07, 12.13it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  21%|███▌             | 25/119 [00:02<00:07, 12.12it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  22%|███▋             | 26/119 [00:02<00:07, 12.10it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  23%|███▊             | 27/119 [00:02<00:07, 12.17it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  24%|████             | 28/119 [00:02<00:07, 12.16it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  24%|████▏            | 29/119 [00:02<00:07, 12.20it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  25%|████▎            | 30/119 [00:02<00:07, 12.25it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  26%|████▍            | 31/119 [00:02<00:07, 12.27it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  27%|████▌            | 32/119 [00:02<00:07, 12.31it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  28%|████▋            | 33/119 [00:02<00:06, 12.33it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  29%|████▊            | 34/119 [00:02<00:06, 12.36it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  29%|█████            | 35/119 [00:02<00:06, 12.33it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  30%|█████▏           | 36/119 [00:02<00:06, 12.37it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  31%|█████▎           | 37/119 [00:02<00:06, 12.39it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  32%|█████▍           | 38/119 [00:03<00:06, 12.41it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  33%|█████▌           | 39/119 [00:03<00:06, 12.42it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  34%|█████▋           | 40/119 [00:03<00:06, 12.45it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  34%|█████▊           | 41/119 [00:03<00:06, 12.48it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  35%|██████           | 42/119 [00:03<00:06, 12.48it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  36%|██████▏          | 43/119 [00:03<00:06, 12.49it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  37%|██████▎          | 44/119 [00:03<00:06, 12.50it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  38%|██████▍          | 45/119 [00:03<00:05, 12.48it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  39%|██████▌          | 46/119 [00:03<00:05, 12.48it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  39%|██████▋          | 47/119 [00:03<00:05, 12.50it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  40%|██████▊          | 48/119 [00:03<00:05, 12.50it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  41%|███████          | 49/119 [00:03<00:05, 12.51it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  42%|███████▏         | 50/119 [00:03<00:05, 12.51it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  43%|███████▎         | 51/119 [00:04<00:05, 12.52it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  44%|███████▍         | 52/119 [00:04<00:05, 12.52it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  45%|███████▌         | 53/119 [00:04<00:05, 12.54it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  45%|███████▋         | 54/119 [00:04<00:05, 12.55it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  46%|███████▊         | 55/119 [00:04<00:05, 12.57it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  47%|████████         | 56/119 [00:04<00:05, 12.56it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  48%|████████▏        | 57/119 [00:04<00:04, 12.57it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  49%|████████▎        | 58/119 [00:04<00:04, 12.59it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  50%|████████▍        | 59/119 [00:04<00:04, 12.59it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  50%|████████▌        | 60/119 [00:04<00:04, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  51%|████████▋        | 61/119 [00:04<00:04, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  52%|████████▊        | 62/119 [00:04<00:04, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  53%|█████████        | 63/119 [00:04<00:04, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  54%|█████████▏       | 64/119 [00:05<00:04, 12.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  55%|█████████▎       | 65/119 [00:05<00:04, 12.66it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  55%|█████████▍       | 66/119 [00:05<00:04, 12.67it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  56%|█████████▌       | 67/119 [00:05<00:04, 12.67it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  57%|█████████▋       | 68/119 [00:05<00:04, 12.68it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  58%|█████████▊       | 69/119 [00:05<00:03, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  59%|██████████       | 70/119 [00:05<00:03, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  60%|██████████▏      | 71/119 [00:05<00:03, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  61%|██████████▎      | 72/119 [00:05<00:03, 12.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  61%|██████████▍      | 73/119 [00:05<00:03, 12.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  62%|██████████▌      | 74/119 [00:05<00:03, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  63%|██████████▋      | 75/119 [00:05<00:03, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  64%|██████████▊      | 76/119 [00:06<00:03, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  65%|███████████      | 77/119 [00:06<00:03, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  66%|███████████▏     | 78/119 [00:06<00:03, 12.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  66%|███████████▎     | 79/119 [00:06<00:03, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  67%|███████████▍     | 80/119 [00:06<00:03, 12.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  68%|███████████▌     | 81/119 [00:06<00:03, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  69%|███████████▋     | 82/119 [00:06<00:02, 12.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  70%|███████████▊     | 83/119 [00:06<00:02, 12.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  71%|████████████     | 84/119 [00:06<00:02, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  71%|████████████▏    | 85/119 [00:06<00:02, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  72%|████████████▎    | 86/119 [00:06<00:02, 12.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  73%|████████████▍    | 87/119 [00:06<00:02, 12.60it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  74%|████████████▌    | 88/119 [00:06<00:02, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  75%|████████████▋    | 89/119 [00:07<00:02, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  76%|████████████▊    | 90/119 [00:07<00:02, 12.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  76%|█████████████    | 91/119 [00:07<00:02, 12.61it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  77%|█████████████▏   | 92/119 [00:07<00:02, 12.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  78%|█████████████▎   | 93/119 [00:07<00:02, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  79%|█████████████▍   | 94/119 [00:07<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  80%|█████████████▌   | 95/119 [00:07<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  81%|█████████████▋   | 96/119 [00:07<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  82%|█████████████▊   | 97/119 [00:07<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  82%|██████████████   | 98/119 [00:07<00:01, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  83%|██████████████▏  | 99/119 [00:07<00:01, 12.62it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  84%|█████████████▍  | 100/119 [00:07<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  85%|█████████████▌  | 101/119 [00:07<00:01, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  86%|█████████████▋  | 102/119 [00:08<00:01, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  87%|█████████████▊  | 103/119 [00:08<00:01, 12.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  87%|█████████████▉  | 104/119 [00:08<00:01, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  88%|██████████████  | 105/119 [00:08<00:01, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  89%|██████████████▎ | 106/119 [00:08<00:01, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  90%|██████████████▍ | 107/119 [00:08<00:00, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  91%|██████████████▌ | 108/119 [00:08<00:00, 12.63it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  92%|██████████████▋ | 109/119 [00:08<00:00, 12.64it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  92%|██████████████▊ | 110/119 [00:08<00:00, 12.65it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  93%|██████████████▉ | 111/119 [00:08<00:00, 12.66it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  94%|███████████████ | 112/119 [00:08<00:00, 12.66it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  95%|███████████████▏| 113/119 [00:08<00:00, 12.68it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  96%|███████████████▎| 114/119 [00:08<00:00, 12.70it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  97%|███████████████▍| 115/119 [00:09<00:00, 12.72it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  97%|███████████████▌| 116/119 [00:09<00:00, 12.74it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  98%|███████████████▋| 117/119 [00:09<00:00, 12.75it/s]\u001b[A\r\n",
      "Validation DataLoader 0:  99%|███████████████▊| 118/119 [00:09<00:00, 12.77it/s]\u001b[A\r\n",
      "Validation DataLoader 0: 100%|████████████████| 119/119 [00:09<00:00, 12.79it/s]\u001b[A\r\n",
      "Epoch 0: 100%|█████████████████| 62236/62236 [1:05:24<00:00, 15.86it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=1` reached.\r\n",
      "Epoch 0: 100%|█████████████████| 62236/62236 [1:05:24<00:00, 15.86it/s, v_num=0]\r\n",
      "2023/11/13 12:19:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\r\n",
      "Exported graph: graph(%item_indices : Long(*, strides=[1], requires_grad=0, device=cpu),\r\n",
      "      %k : Long(requires_grad=0, device=cpu),\r\n",
      "      %model.future_mask_const : Float(50, 50, strides=[50, 1], requires_grad=0, device=cpu),\r\n",
      "      %model.item_embedding.weight : Float(37484, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.positional_embedding_layer.pos_indices_const : Int(50, strides=[1], requires_grad=0, device=cpu),\r\n",
      "      %model.positional_embedding_layer.embedding.weight : Float(50, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.norm.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.norm.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.in_proj_weight : Float(600, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.in_proj_bias : Float(600, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.out_proj.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.self_attn.out_proj.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear1.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear2.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.linear2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm1.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm2.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.0.norm2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.in_proj_weight : Float(600, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.in_proj_bias : Float(600, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.out_proj.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.self_attn.out_proj.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear1.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear2.weight : Float(200, 200, strides=[200, 1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.linear2.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm1.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm1.bias : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm2.weight : Float(200, strides=[1], requires_grad=1, device=cpu),\r\n",
      "      %model.encoder.layers.1.norm2.bias : Float(200, strides=[1], requires_grad=1, device=cpu)):\r\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Shape_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%item_indices), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %onnx::Unsqueeze_38 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze\"](%/Gather_output_0, %onnx::Unsqueeze_38), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Concat_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat\"](%/Unsqueeze_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/ConstantOfShape_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Concat_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_2\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Unsqueeze_1_output_0 : Float(1, *, strides=[15, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_1\"](%/ConstantOfShape_output_0, %/Constant_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_3\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Unsqueeze_2_output_0 : Long(1, *, strides=[15, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_2\"](%item_indices, %/Constant_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:184:0\r\n",
      "  %/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_4\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "  %/Shape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_1\"](%/Unsqueeze_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:114:0\r\n",
      "  %/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_5\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:114:0\r\n",
      "  %/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_1\"](%/Shape_1_output_0, %/Constant_5_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:114:0\r\n",
      "  %/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_6\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_3\"](%/Constant_output_0, %/Constant_6_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_7\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_4\"](%/Gather_1_output_0, %/Constant_7_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_8\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_5\"](%/Constant_output_0, %/Constant_8_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_9\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Slice_output_0 : Float(*, *, strides=[50, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%model.future_mask_const, %/Unsqueeze_3_output_0, %/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0, %/Constant_9_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_10\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_6\"](%/Constant_output_0, %/Constant_10_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_11\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_7\"](%/Gather_1_output_0, %/Constant_11_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_12\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_8\"](%/Constant_4_output_0, %/Constant_12_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_13\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/Slice_1_output_0 : Float(*, *, strides=[50, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/Slice_1\"](%/Slice_output_0, %/Unsqueeze_6_output_0, %/Unsqueeze_7_output_0, %/Unsqueeze_8_output_0, %/Constant_13_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:117:0\r\n",
      "  %/item_embedding/Gather_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name=\"/item_embedding/Gather\"](%model.item_embedding.weight, %/Unsqueeze_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.sparse.Embedding::item_embedding # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2194:0\r\n",
      "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/Constant_14\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:131:0\r\n",
      "  %/Mul_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/item_embedding/Gather_output_0, %/Constant_14_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:131:0\r\n",
      "  %/positional_embedding_layer/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/positional_embedding_layer/Shape\"](%/Mul_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/positional_embedding_layer/Constant\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/positional_embedding_layer/Gather\"](%/positional_embedding_layer/Shape_output_0, %/positional_embedding_layer/Constant_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:26:0\r\n",
      "  %/positional_embedding_layer/Neg_output_0 : Long(requires_grad=0, device=cpu) = onnx::Neg[onnx_name=\"/positional_embedding_layer/Neg\"](%/positional_embedding_layer/Gather_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/positional_embedding_layer/Constant_1\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer\r\n",
      "  %/positional_embedding_layer/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_2\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze\"](%/positional_embedding_layer/Neg_output_0, %/positional_embedding_layer/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_3\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze_1\"](%/positional_embedding_layer/Constant_1_output_0, %/positional_embedding_layer/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/positional_embedding_layer/Constant_4\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/positional_embedding_layer/Unsqueeze_2\"](%/Constant_output_0, %/positional_embedding_layer/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/positional_embedding_layer/Constant_5\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/Slice_output_0 : Int(*, strides=[1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/positional_embedding_layer/Slice\"](%model.positional_embedding_layer.pos_indices_const, %/positional_embedding_layer/Unsqueeze_output_0, %/positional_embedding_layer/Unsqueeze_1_output_0, %/positional_embedding_layer/Unsqueeze_2_output_0, %/positional_embedding_layer/Constant_5_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/positional_embedding_layer/embedding/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/positional_embedding_layer/embedding/Constant\"](), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer/torch.nn.modules.sparse.Embedding::embedding\r\n",
      "  %/positional_embedding_layer/embedding/Gather_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name=\"/positional_embedding_layer/embedding/Gather\"](%model.positional_embedding_layer.embedding.weight, %/positional_embedding_layer/Slice_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer/torch.nn.modules.sparse.Embedding::embedding # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2194:0\r\n",
      "  %/positional_embedding_layer/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/positional_embedding_layer/Add\"](%/positional_embedding_layer/embedding/Gather_output_0, %/Mul_output_0), scope: src.sasrec.model.TopKModel::/src.sasrec.model.DynamicPositionEmbedding::positional_embedding_layer # /kaggle/working/TRON/src/sasrec/model.py:27:0\r\n",
      "  %/encoder/layers.0/norm1/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm1/ReduceMean\"](%/positional_embedding_layer/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.0/norm1/Sub\"](%/positional_embedding_layer/Add_output_0, %/encoder/layers.0/norm1/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/norm1/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.0/norm1/Pow\"](%/encoder/layers.0/norm1/Sub_output_0, %/encoder/layers.0/norm1/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm1/ReduceMean_1\"](%/encoder/layers.0/norm1/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.0/norm1/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm1/Add\"](%/encoder/layers.0/norm1/ReduceMean_1_output_0, %/encoder/layers.0/norm1/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.0/norm1/Sqrt\"](%/encoder/layers.0/norm1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/norm1/Div\"](%/encoder/layers.0/norm1/Sub_output_0, %/encoder/layers.0/norm1/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/norm1/Mul\"](%/encoder/layers.0/norm1/Div_output_0, %model.encoder.layers.0.norm1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm1/Add_1\"](%/encoder/layers.0/norm1/Mul_output_0, %model.encoder.layers.0.norm1.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_output_0 : Float(*, 1, 200, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose\"](%/encoder/layers.0/norm1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/activation.py:1099:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather\"](%/encoder/layers.0/self_attn/Shape_output_0, %/encoder/layers.0/self_attn/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_1\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_1\"](%/encoder/layers.0/self_attn/Shape_1_output_0, %/encoder/layers.0/self_attn/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_2\"](%/encoder/layers.0/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_2\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_2\"](%/encoder/layers.0/self_attn/Shape_2_output_0, %/encoder/layers.0/self_attn/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_3\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div\"](%/encoder/layers.0/self_attn/Gather_2_output_0, %/encoder/layers.0/self_attn/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.0/self_attn/Cast\"](%/encoder/layers.0/self_attn/Div_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.0/self_attn/Cast_1\"](%/encoder/layers.0/self_attn/Cast_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_1_output_0 : Float(200, 600, strides=[600, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/self_attn/Transpose_1\"](%model.encoder.layers.0.self_attn.in_proj_weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_output_0 : Float(*, 1, 600, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul\"](%/encoder/layers.0/self_attn/Transpose_output_0, %/encoder/layers.0/self_attn/Transpose_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_output_0 : Float(*, 1, 600, strides=[600, 600, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add\"](%model.encoder.layers.0.self_attn.in_proj_bias, %/encoder/layers.0/self_attn/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_3\"](%/encoder/layers.0/self_attn/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_4\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_3\"](%/encoder/layers.0/self_attn/Shape_3_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_5\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_6\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add_1\"](%/encoder/layers.0/self_attn/Gather_3_output_0, %/encoder/layers.0/self_attn/Constant_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.0/self_attn/Constant_7\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div_1\"](%/encoder/layers.0/self_attn/Add_1_output_0, %/encoder/layers.0/self_attn/Constant_7_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_8\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Constant_5_output_0, %/encoder/layers.0/self_attn/Mul_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/self_attn/Constant_9\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_1\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice_1\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Mul_output_0, %/encoder/layers.0/self_attn/Mul_1_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.0/self_attn/Constant_10\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_2\"](%/encoder/layers.0/self_attn/Div_1_output_0, %/encoder/layers.0/self_attn/Constant_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Slice_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.0/self_attn/Slice_2\"](%/encoder/layers.0/self_attn/Add_output_0, %/encoder/layers.0/self_attn/Mul_1_output_0, %/encoder/layers.0/self_attn/Mul_2_output_0, %/encoder/layers.0/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_11\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5037:0\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_output_0 : Float(1, *, *, strides=[750, 50, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze\"](%/Slice_1_output_0, %/encoder/layers.0/self_attn/Constant_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5037:0\r\n",
      "  %onnx::Unsqueeze_132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_1\"](%/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_132), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_2\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_134), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_3\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_136), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat\"](%/encoder/layers.0/self_attn/Unsqueeze_1_output_0, %/encoder/layers.0/self_attn/Unsqueeze_2_output_0, %/encoder/layers.0/self_attn/Unsqueeze_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape\"](%/encoder/layers.0/self_attn/Slice_output_0, %/encoder/layers.0/self_attn/Concat_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_2\"](%/encoder/layers.0/self_attn/Reshape_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_4\"](%/encoder/layers.0/self_attn/Slice_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_12\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_4\"](%/encoder/layers.0/self_attn/Shape_4_output_0, %/encoder/layers.0/self_attn/Constant_12_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %onnx::Unsqueeze_144 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_4\"](%/encoder/layers.0/self_attn/Gather_4_output_0, %onnx::Unsqueeze_144), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_5\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_146), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_6\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_148), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_1\"](%/encoder/layers.0/self_attn/Unsqueeze_4_output_0, %/encoder/layers.0/self_attn/Unsqueeze_5_output_0, %/encoder/layers.0/self_attn/Unsqueeze_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_1\"](%/encoder/layers.0/self_attn/Slice_1_output_0, %/encoder/layers.0/self_attn/Concat_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_5\"](%/encoder/layers.0/self_attn/Slice_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_13_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.0/self_attn/Constant_13\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_5\"](%/encoder/layers.0/self_attn/Shape_5_output_0, %/encoder/layers.0/self_attn/Constant_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %onnx::Unsqueeze_155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_7\"](%/encoder/layers.0/self_attn/Gather_5_output_0, %onnx::Unsqueeze_155), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_8\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_157), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_9\"](%/encoder/layers.0/self_attn/Cast_1_output_0, %onnx::Unsqueeze_159), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_2\"](%/encoder/layers.0/self_attn/Unsqueeze_7_output_0, %/encoder/layers.0/self_attn/Unsqueeze_8_output_0, %/encoder/layers.0/self_attn/Unsqueeze_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_2\"](%/encoder/layers.0/self_attn/Slice_2_output_0, %/encoder/layers.0/self_attn/Concat_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_3\"](%/encoder/layers.0/self_attn/Reshape_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/encoder/layers.0/self_attn/Constant_14\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.0/self_attn/Div_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/self_attn/Div_2\"](%/encoder/layers.0/self_attn/Transpose_2_output_0, %/encoder/layers.0/self_attn/Constant_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[200, 1, 200], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 2, 0], onnx_name=\"/encoder/layers.0/self_attn/Transpose_4\"](%/encoder/layers.0/self_attn/Reshape_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_1_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul_1\"](%/encoder/layers.0/self_attn/Div_2_output_0, %/encoder/layers.0/self_attn/Transpose_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.0/self_attn/Cast_2\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_3\"](%/encoder/layers.0/self_attn/MatMul_1_output_0, %/encoder/layers.0/self_attn/Cast_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.0/self_attn/Cast_3\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_4_output_0 : Float(1, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_4\"](%/encoder/layers.0/self_attn/Unsqueeze_output_0, %/encoder/layers.0/self_attn/Cast_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Add_2_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/self_attn/Add_2\"](%/encoder/layers.0/self_attn/Mul_3_output_0, %/encoder/layers.0/self_attn/Mul_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.0/self_attn/Softmax_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/encoder/layers.0/self_attn/Softmax\"](%/encoder/layers.0/self_attn/Add_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\r\n",
      "  %/encoder/layers.0/self_attn/MatMul_2_output_0 : Float(*, *, *, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/self_attn/MatMul_2\"](%/encoder/layers.0/self_attn/Softmax_output_0, %/encoder/layers.0/self_attn/Transpose_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_5_output_0 : Float(*, *, *, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_5\"](%/encoder/layers.0/self_attn/MatMul_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/self_attn/Mul_5\"](%/encoder/layers.0/self_attn/Gather_output_0, %/encoder/layers.0/self_attn/Gather_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %onnx::Unsqueeze_177 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_10\"](%/encoder/layers.0/self_attn/Mul_5_output_0, %onnx::Unsqueeze_177), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_11\"](%/encoder/layers.0/self_attn/Gather_2_output_0, %onnx::Unsqueeze_179), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_3\"](%/encoder/layers.0/self_attn/Unsqueeze_10_output_0, %/encoder/layers.0/self_attn/Unsqueeze_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_3_output_0 : Float(*, *, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_3\"](%/encoder/layers.0/self_attn/Transpose_5_output_0, %/encoder/layers.0/self_attn/Concat_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.0/self_attn/Gemm_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/encoder/layers.0/self_attn/Gemm\"](%/encoder/layers.0/self_attn/Reshape_3_output_0, %model.encoder.layers.0.self_attn.out_proj.weight, %model.encoder.layers.0.self_attn.out_proj.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.0/self_attn/Shape_6\"](%/encoder/layers.0/self_attn/Gemm_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Constant_15_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.0/self_attn/Constant_15\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Gather_6\"](%/encoder/layers.0/self_attn/Shape_6_output_0, %/encoder/layers.0/self_attn/Constant_15_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %onnx::Unsqueeze_187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_12\"](%/encoder/layers.0/self_attn/Gather_output_0, %onnx::Unsqueeze_187), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_13\"](%/encoder/layers.0/self_attn/Gather_1_output_0, %onnx::Unsqueeze_189), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.0/self_attn/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.0/self_attn/Unsqueeze_14\"](%/encoder/layers.0/self_attn/Gather_6_output_0, %onnx::Unsqueeze_191), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.0/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.0/self_attn/Concat_4\"](%/encoder/layers.0/self_attn/Unsqueeze_12_output_0, %/encoder/layers.0/self_attn/Unsqueeze_13_output_0, %/encoder/layers.0/self_attn/Unsqueeze_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Reshape_4_output_0 : Float(*, 1, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.0/self_attn/Reshape_4\"](%/encoder/layers.0/self_attn/Gemm_output_0, %/encoder/layers.0/self_attn/Concat_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.0/self_attn/Transpose_6_output_0 : Float(1, *, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.0/self_attn/Transpose_6\"](%/encoder/layers.0/self_attn/Reshape_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/activation.py:1121:0\r\n",
      "  %/encoder/layers.0/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/Add\"](%/positional_embedding_layer/Add_output_0, %/encoder/layers.0/self_attn/Transpose_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/transformer.py:491:0\r\n",
      "  %/encoder/layers.0/norm2/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm2/ReduceMean\"](%/encoder/layers.0/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.0/norm2/Sub\"](%/encoder/layers.0/Add_output_0, %/encoder/layers.0/norm2/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.0/norm2/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.0/norm2/Pow\"](%/encoder/layers.0/norm2/Sub_output_0, %/encoder/layers.0/norm2/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.0/norm2/ReduceMean_1\"](%/encoder/layers.0/norm2/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.0/norm2/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm2/Add\"](%/encoder/layers.0/norm2/ReduceMean_1_output_0, %/encoder/layers.0/norm2/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.0/norm2/Sqrt\"](%/encoder/layers.0/norm2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.0/norm2/Div\"](%/encoder/layers.0/norm2/Sub_output_0, %/encoder/layers.0/norm2/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.0/norm2/Mul\"](%/encoder/layers.0/norm2/Div_output_0, %model.encoder.layers.0.norm2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/norm2/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/norm2/Add_1\"](%/encoder/layers.0/norm2/Mul_output_0, %model.encoder.layers.0.norm2.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.0/linear1/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/linear1/Transpose\"](%model.encoder.layers.0.linear1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear1/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/linear1/MatMul\"](%/encoder/layers.0/norm2/Add_1_output_0, %/encoder/layers.0/linear1/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/linear1/Add\"](%model.encoder.layers.0.linear1.bias, %/encoder/layers.0/linear1/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/Relu_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/layers.0/Relu\"](%/encoder/layers.0/linear1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\r\n",
      "  %/encoder/layers.0/linear2/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.0/linear2/Transpose\"](%model.encoder.layers.0.linear2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear2/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.0/linear2/MatMul\"](%/encoder/layers.0/Relu_output_0, %/encoder/layers.0/linear2/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/linear2/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/linear2/Add\"](%model.encoder.layers.0.linear2.bias, %/encoder/layers.0/linear2/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.0/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.0/Add_1\"](%/encoder/layers.0/Add_output_0, %/encoder/layers.0/linear2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.0 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/transformer.py:492:0\r\n",
      "  %/encoder/layers.1/norm1/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm1/ReduceMean\"](%/encoder/layers.0/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.1/norm1/Sub\"](%/encoder/layers.0/Add_1_output_0, %/encoder/layers.1/norm1/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/norm1/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.1/norm1/Pow\"](%/encoder/layers.1/norm1/Sub_output_0, %/encoder/layers.1/norm1/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm1/ReduceMean_1\"](%/encoder/layers.1/norm1/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.1/norm1/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm1/Add\"](%/encoder/layers.1/norm1/ReduceMean_1_output_0, %/encoder/layers.1/norm1/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.1/norm1/Sqrt\"](%/encoder/layers.1/norm1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/norm1/Div\"](%/encoder/layers.1/norm1/Sub_output_0, %/encoder/layers.1/norm1/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/norm1/Mul\"](%/encoder/layers.1/norm1/Div_output_0, %model.encoder.layers.1.norm1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm1/Add_1\"](%/encoder/layers.1/norm1/Mul_output_0, %model.encoder.layers.1.norm1.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_output_0 : Float(*, 1, 200, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose\"](%/encoder/layers.1/norm1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/activation.py:1099:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather\"](%/encoder/layers.1/self_attn/Shape_output_0, %/encoder/layers.1/self_attn/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_1\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_1\"](%/encoder/layers.1/self_attn/Shape_1_output_0, %/encoder/layers.1/self_attn/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_2\"](%/encoder/layers.1/self_attn/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_2\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_2\"](%/encoder/layers.1/self_attn/Shape_2_output_0, %/encoder/layers.1/self_attn/Constant_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5001:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_3\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_output_0 : Long(device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div\"](%/encoder/layers.1/self_attn/Gather_2_output_0, %/encoder/layers.1/self_attn/Constant_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.1/self_attn/Cast\"](%/encoder/layers.1/self_attn/Div_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name=\"/encoder/layers.1/self_attn/Cast_1\"](%/encoder/layers.1/self_attn/Cast_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5014:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_1_output_0 : Float(200, 600, strides=[600, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/self_attn/Transpose_1\"](%model.encoder.layers.1.self_attn.in_proj_weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_output_0 : Float(*, 1, 600, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul\"](%/encoder/layers.1/self_attn/Transpose_output_0, %/encoder/layers.1/self_attn/Transpose_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_output_0 : Float(*, 1, 600, strides=[600, 600, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add\"](%model.encoder.layers.1.self_attn.in_proj_bias, %/encoder/layers.1/self_attn/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4734:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_3\"](%/encoder/layers.1/self_attn/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_4\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_3\"](%/encoder/layers.1/self_attn/Shape_3_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_5\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_6\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add_1\"](%/encoder/layers.1/self_attn/Gather_3_output_0, %/encoder/layers.1/self_attn/Constant_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.1/self_attn/Constant_7\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div_1\"](%/encoder/layers.1/self_attn/Add_1_output_0, %/encoder/layers.1/self_attn/Constant_7_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_8\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Constant_5_output_0, %/encoder/layers.1/self_attn/Mul_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/self_attn/Constant_9\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_1\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_9_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice_1\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Mul_output_0, %/encoder/layers.1/self_attn/Mul_1_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name=\"/encoder/layers.1/self_attn/Constant_10\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_2\"](%/encoder/layers.1/self_attn/Div_1_output_0, %/encoder/layers.1/self_attn/Constant_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %/encoder/layers.1/self_attn/Slice_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name=\"/encoder/layers.1/self_attn/Slice_2\"](%/encoder/layers.1/self_attn/Add_output_0, %/encoder/layers.1/self_attn/Mul_1_output_0, %/encoder/layers.1/self_attn/Mul_2_output_0, %/encoder/layers.1/self_attn/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:4735:0\r\n",
      "  %onnx::Unsqueeze_261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze\"](%/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_261), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_1\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_263), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_2\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_265), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat\"](%/encoder/layers.1/self_attn/Unsqueeze_output_0, %/encoder/layers.1/self_attn/Unsqueeze_1_output_0, %/encoder/layers.1/self_attn/Unsqueeze_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape\"](%/encoder/layers.1/self_attn/Slice_output_0, %/encoder/layers.1/self_attn/Concat_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_2\"](%/encoder/layers.1/self_attn/Reshape_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5050:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_4\"](%/encoder/layers.1/self_attn/Slice_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_11\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_4\"](%/encoder/layers.1/self_attn/Shape_4_output_0, %/encoder/layers.1/self_attn/Constant_11_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5051:0\r\n",
      "  %onnx::Unsqueeze_273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_3\"](%/encoder/layers.1/self_attn/Gather_4_output_0, %onnx::Unsqueeze_273), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_4\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_275), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_5\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_277), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_1\"](%/encoder/layers.1/self_attn/Unsqueeze_3_output_0, %/encoder/layers.1/self_attn/Unsqueeze_4_output_0, %/encoder/layers.1/self_attn/Unsqueeze_5_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_1_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_1\"](%/encoder/layers.1/self_attn/Slice_1_output_0, %/encoder/layers.1/self_attn/Concat_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5052:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_5\"](%/encoder/layers.1/self_attn/Slice_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_12_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/encoder/layers.1/self_attn/Constant_12\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_5\"](%/encoder/layers.1/self_attn/Shape_5_output_0, %/encoder/layers.1/self_attn/Constant_12_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5058:0\r\n",
      "  %onnx::Unsqueeze_284 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_6\"](%/encoder/layers.1/self_attn/Gather_5_output_0, %onnx::Unsqueeze_284), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_286 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_7\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_286), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_288 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_8\"](%/encoder/layers.1/self_attn/Cast_1_output_0, %onnx::Unsqueeze_288), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_2\"](%/encoder/layers.1/self_attn/Unsqueeze_6_output_0, %/encoder/layers.1/self_attn/Unsqueeze_7_output_0, %/encoder/layers.1/self_attn/Unsqueeze_8_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_2\"](%/encoder/layers.1/self_attn/Slice_2_output_0, %/encoder/layers.1/self_attn/Concat_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_3_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_3\"](%/encoder/layers.1/self_attn/Reshape_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5059:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={14.1421}, onnx_name=\"/encoder/layers.1/self_attn/Constant_13\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.1/self_attn/Div_2_output_0 : Float(*, *, *, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/self_attn/Div_2\"](%/encoder/layers.1/self_attn/Transpose_2_output_0, %/encoder/layers.1/self_attn/Constant_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5079:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_4_output_0 : Float(*, *, *, strides=[200, 1, 200], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 2, 0], onnx_name=\"/encoder/layers.1/self_attn/Transpose_4\"](%/encoder/layers.1/self_attn/Reshape_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_1_output_0 : Float(*, *, *, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul_1\"](%/encoder/layers.1/self_attn/Div_2_output_0, %/encoder/layers.1/self_attn/Transpose_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_2_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.1/self_attn/Cast_2\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_3_output_0 : Float(*, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_3\"](%/encoder/layers.1/self_attn/MatMul_1_output_0, %/encoder/layers.1/self_attn/Cast_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name=\"/encoder/layers.1/self_attn/Cast_3\"](%/Constant_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_4_output_0 : Float(1, *, *, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_4\"](%/encoder/layers.0/self_attn/Unsqueeze_output_0, %/encoder/layers.1/self_attn/Cast_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Add_2_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/self_attn/Add_2\"](%/encoder/layers.1/self_attn/Mul_3_output_0, %/encoder/layers.1/self_attn/Mul_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5080:0\r\n",
      "  %/encoder/layers.1/self_attn/Softmax_output_0 : Float(*, *, *, strides=[225, 15, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name=\"/encoder/layers.1/self_attn/Softmax\"](%/encoder/layers.1/self_attn/Add_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:1838:0\r\n",
      "  %/encoder/layers.1/self_attn/MatMul_2_output_0 : Float(*, *, *, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/self_attn/MatMul_2\"](%/encoder/layers.1/self_attn/Softmax_output_0, %/encoder/layers.1/self_attn/Transpose_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_5_output_0 : Float(*, *, *, strides=[200, 3000, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_5\"](%/encoder/layers.1/self_attn/MatMul_2_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Mul_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/self_attn/Mul_5\"](%/encoder/layers.1/self_attn/Gather_output_0, %/encoder/layers.1/self_attn/Gather_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %onnx::Unsqueeze_306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_9\"](%/encoder/layers.1/self_attn/Mul_5_output_0, %onnx::Unsqueeze_306), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_10\"](%/encoder/layers.1/self_attn/Gather_2_output_0, %onnx::Unsqueeze_308), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_3\"](%/encoder/layers.1/self_attn/Unsqueeze_9_output_0, %/encoder/layers.1/self_attn/Unsqueeze_10_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_3_output_0 : Float(*, *, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_3\"](%/encoder/layers.1/self_attn/Transpose_5_output_0, %/encoder/layers.1/self_attn/Concat_3_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5082:0\r\n",
      "  %/encoder/layers.1/self_attn/Gemm_output_0 : Float(*, 200, strides=[200, 1], requires_grad=0, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/encoder/layers.1/self_attn/Gemm\"](%/encoder/layers.1/self_attn/Reshape_3_output_0, %model.encoder.layers.1.self_attn.out_proj.weight, %model.encoder.layers.1.self_attn.out_proj.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/encoder/layers.1/self_attn/Shape_6\"](%/encoder/layers.1/self_attn/Gemm_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Constant_14_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/encoder/layers.1/self_attn/Constant_14\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Gather_6\"](%/encoder/layers.1/self_attn/Shape_6_output_0, %/encoder/layers.1/self_attn/Constant_14_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %onnx::Unsqueeze_316 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_11\"](%/encoder/layers.1/self_attn/Gather_output_0, %onnx::Unsqueeze_316), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_12\"](%/encoder/layers.1/self_attn/Gather_1_output_0, %onnx::Unsqueeze_318), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %onnx::Unsqueeze_320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\r\n",
      "  %/encoder/layers.1/self_attn/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/encoder/layers.1/self_attn/Unsqueeze_13\"](%/encoder/layers.1/self_attn/Gather_6_output_0, %onnx::Unsqueeze_320), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn\r\n",
      "  %/encoder/layers.1/self_attn/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/encoder/layers.1/self_attn/Concat_4\"](%/encoder/layers.1/self_attn/Unsqueeze_11_output_0, %/encoder/layers.1/self_attn/Unsqueeze_12_output_0, %/encoder/layers.1/self_attn/Unsqueeze_13_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Reshape_4_output_0 : Float(*, 1, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/encoder/layers.1/self_attn/Reshape_4\"](%/encoder/layers.1/self_attn/Gemm_output_0, %/encoder/layers.1/self_attn/Concat_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:5083:0\r\n",
      "  %/encoder/layers.1/self_attn/Transpose_6_output_0 : Float(1, *, 200, strides=[200, 200, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/encoder/layers.1/self_attn/Transpose_6\"](%/encoder/layers.1/self_attn/Reshape_4_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.activation.MultiheadAttention::self_attn # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/activation.py:1121:0\r\n",
      "  %/encoder/layers.1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/Add\"](%/encoder/layers.0/Add_1_output_0, %/encoder/layers.1/self_attn/Transpose_6_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/transformer.py:491:0\r\n",
      "  %/encoder/layers.1/norm2/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm2/ReduceMean\"](%/encoder/layers.1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/layers.1/norm2/Sub\"](%/encoder/layers.1/Add_output_0, %/encoder/layers.1/norm2/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/layers.1/norm2/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/layers.1/norm2/Pow\"](%/encoder/layers.1/norm2/Sub_output_0, %/encoder/layers.1/norm2/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/layers.1/norm2/ReduceMean_1\"](%/encoder/layers.1/norm2/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/layers.1/norm2/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm2/Add\"](%/encoder/layers.1/norm2/ReduceMean_1_output_0, %/encoder/layers.1/norm2/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/layers.1/norm2/Sqrt\"](%/encoder/layers.1/norm2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/layers.1/norm2/Div\"](%/encoder/layers.1/norm2/Sub_output_0, %/encoder/layers.1/norm2/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/layers.1/norm2/Mul\"](%/encoder/layers.1/norm2/Div_output_0, %model.encoder.layers.1.norm2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/norm2/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/norm2/Add_1\"](%/encoder/layers.1/norm2/Mul_output_0, %model.encoder.layers.1.norm2.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.normalization.LayerNorm::norm2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/layers.1/linear1/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/linear1/Transpose\"](%model.encoder.layers.1.linear1.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear1/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/linear1/MatMul\"](%/encoder/layers.1/norm2/Add_1_output_0, %/encoder/layers.1/linear1/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear1/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/linear1/Add\"](%model.encoder.layers.1.linear1.bias, %/encoder/layers.1/linear1/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/Relu_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/encoder/layers.1/Relu\"](%/encoder/layers.1/linear1/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\r\n",
      "  %/encoder/layers.1/linear2/Transpose_output_0 : Float(200, 200, strides=[200, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/encoder/layers.1/linear2/Transpose\"](%model.encoder.layers.1.linear2.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear2/MatMul_output_0 : Float(1, *, 200, device=cpu) = onnx::MatMul[onnx_name=\"/encoder/layers.1/linear2/MatMul\"](%/encoder/layers.1/Relu_output_0, %/encoder/layers.1/linear2/Transpose_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/linear2/Add_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/linear2/Add\"](%model.encoder.layers.1.linear2.bias, %/encoder/layers.1/linear2/MatMul_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1/torch.nn.modules.linear.Linear::linear2 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\r\n",
      "  %/encoder/layers.1/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/layers.1/Add_1\"](%/encoder/layers.1/Add_output_0, %/encoder/layers.1/linear2/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.transformer.TransformerEncoderLayer::layers.1 # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/modules/transformer.py:492:0\r\n",
      "  %/encoder/norm/ReduceMean_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/norm/ReduceMean\"](%/encoder/layers.1/Add_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Sub_output_0 : Float(1, *, 200, device=cpu) = onnx::Sub[onnx_name=\"/encoder/norm/Sub\"](%/encoder/layers.1/Add_1_output_0, %/encoder/norm/ReduceMean_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/encoder/norm/Constant\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Pow_output_0 : Float(1, *, 200, device=cpu) = onnx::Pow[onnx_name=\"/encoder/norm/Pow\"](%/encoder/norm/Sub_output_0, %/encoder/norm/Constant_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/ReduceMean_1_output_0 : Float(1, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/encoder/norm/ReduceMean_1\"](%/encoder/norm/Pow_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/encoder/norm/Constant_1\"](), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Add_output_0 : Float(1, *, 1, device=cpu) = onnx::Add[onnx_name=\"/encoder/norm/Add\"](%/encoder/norm/ReduceMean_1_output_0, %/encoder/norm/Constant_1_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Sqrt_output_0 : Float(1, *, 1, device=cpu) = onnx::Sqrt[onnx_name=\"/encoder/norm/Sqrt\"](%/encoder/norm/Add_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Div_output_0 : Float(1, *, 200, device=cpu) = onnx::Div[onnx_name=\"/encoder/norm/Div\"](%/encoder/norm/Sub_output_0, %/encoder/norm/Sqrt_output_0), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Mul_output_0 : Float(1, *, 200, device=cpu) = onnx::Mul[onnx_name=\"/encoder/norm/Mul\"](%/encoder/norm/Div_output_0, %model.norm.weight), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/encoder/norm/Add_1_output_0 : Float(1, *, 200, strides=[3000, 200, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/encoder/norm/Add_1\"](%/encoder/norm/Mul_output_0, %model.norm.bias), scope: src.sasrec.model.TopKModel::/torch.nn.modules.transformer.TransformerEncoder::encoder/torch.nn.modules.normalization.LayerNorm::norm # /root/.local/share/virtualenvs/TRON-qh2Xl1Tx/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\r\n",
      "  %/Gather_2_output_0 : Float(1, 200, strides=[3000, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name=\"/Gather_2\"](%/encoder/norm/Add_1_output_0, %/positional_embedding_layer/embedding/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:185:0\r\n",
      "  %/Transpose_output_0 : Float(200, 37484, strides=[1, 200], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name=\"/Transpose\"](%model.item_embedding.weight), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/shared/logits_computation.py:5:0\r\n",
      "  %/MatMul_output_0 : Float(1, 37484, strides=[37484, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name=\"/MatMul\"](%/Gather_2_output_0, %/Transpose_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/shared/logits_computation.py:5:0\r\n",
      "  %/Gather_3_output_0 : Float(37484, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_3\"](%/MatMul_output_0, %/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Gather_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_4\"](%/Gather_3_output_0, %/Constant_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}, onnx_name=\"/Constant_15\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_2\"](%/Gather_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_output_0 : Float(requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_15_output_0, %/Shape_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_16\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_17_output_0 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_17\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_18_output_0 : Long(1, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_18\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_19\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Add_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Constant_18_output_0, %/Constant_19_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_3\"](%/Add_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_4\"](%/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Shape_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_20_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_20\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_20_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Shape_3_output_0, %/Mul_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Where_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_1_output_0, %/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_1_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_17_output_0, %/Where_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_21\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Unsqueeze_9_output_0 : Long(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_9\"](%/Expand_1_output_0, %/Constant_21_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_5\"](%/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Shape_5_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_22_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_22\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_1_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Shape_3_output_0, %/Mul_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Where_1_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_2_output_0, %/Shape_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_2_output_0 : Long(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Constant_16_output_0, %/Where_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_23\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Unsqueeze_10_output_0 : Long(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_10\"](%/Expand_2_output_0, %/Constant_23_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Concat_1_output_0 : Long(1, 1, 2, strides=[2, 2, 1], device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Unsqueeze_9_output_0, %/Unsqueeze_10_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_6_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_6\"](%/MatMul_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_24\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_25\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_26\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Slice_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice_2\"](%/Shape_6_output_0, %/Constant_25_output_0, %/Constant_26_output_0, %/Constant_24_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Concat_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_2\"](%/Shape_3_output_0, %/Slice_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_7\"](%/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/ConstantOfShape_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Shape_7_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_27_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_27\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Mul_3_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/ConstantOfShape_3_output_0, %/Constant_27_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_2_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Concat_2_output_0, %/Mul_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Where_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_3_output_0, %/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Expand_3_output_0 : Float(1, 1, strides=[1, 1], device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%/Expand_output_0, %/Where_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Reshape_output_0 : Float(1, 1, strides=[1, 1], device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Expand_3_output_0, %/Concat_2_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/ScatterND_output_0 : Float(1, 37484, requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name=\"/ScatterND\"](%/MatMul_output_0, %/Concat_1_output_0, %/Reshape_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_28\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Reshape_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%k, %/Constant_28_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/TopK_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu), %/TopK_output_1 : Long(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1, onnx_name=\"/TopK\"](%/ScatterND_output_0, %/Reshape_1_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_29\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Shape_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_8\"](%/TopK_output_1), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Gather_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_5\"](%/Shape_8_output_0, %/Constant_29_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_30\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %/Equal_3_output_0 : Bool(1, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Gather_5_output_0, %/Constant_30_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "  %indices : Long(*, device=cpu) = onnx::If[onnx_name=\"/If\"](%/Equal_3_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:186:0\r\n",
      "    block0():\r\n",
      "      %/Constant_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_31\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "      %/Squeeze_output_0 : Long(*, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze\"](%/TopK_output_1, %/Constant_31_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Squeeze_output_0)\r\n",
      "    block1():\r\n",
      "      %/Identity_output_0 : Long(*, *, device=cpu) = onnx::Identity[onnx_name=\"/Identity\"](%/TopK_output_1), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Identity_output_0)\r\n",
      "  %/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_32\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "  %/Shape_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape_9\"](%/TopK_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "  %/Gather_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather_6\"](%/Shape_9_output_0, %/Constant_32_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "  %/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_33\"](), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "  %/Equal_4_output_0 : Bool(1, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Gather_6_output_0, %/Constant_33_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "  %scores : Float(*, device=cpu) = onnx::If[onnx_name=\"/If_1\"](%/Equal_4_output_0), scope: src.sasrec.model.TopKModel:: # /kaggle/working/TRON/src/sasrec/model.py:187:0\r\n",
      "    block0():\r\n",
      "      %/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_34\"](), scope: src.sasrec.model.TopKModel::\r\n",
      "      %/Squeeze_1_output_0 : Float(*, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze_1\"](%/TopK_output_0, %/Constant_34_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Squeeze_1_output_0)\r\n",
      "    block1():\r\n",
      "      %/Identity_1_output_0 : Float(*, *, device=cpu) = onnx::Identity[onnx_name=\"/Identity_1\"](%/TopK_output_0), scope: src.sasrec.model.TopKModel::\r\n",
      "      -> (%/Identity_1_output_0)\r\n",
      "  return (%indices, %scores)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pipenv run python -m src --config-filename tron/yoochoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a203f6",
   "metadata": {
    "papermill": {
     "duration": 6.192553,
     "end_time": "2023-11-13T12:19:42.114477",
     "exception": false,
     "start_time": "2023-11-13T12:19:35.921924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 55175,
     "sourceId": 105481,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5178.408977,
   "end_time": "2023-11-13T12:19:48.766774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-13T10:53:30.357797",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
